Applications of robotics are broad and constantly changing as we uncover more of what robots are able to accomplish and how they are able to help us. As such, it is crucial that we continue to develop robotic systems that can operate in a variety of environments. In order to meet this demand, over the past decade we have seen many companies successfully develop and market robots with different shapes and skill sets. Among these, Clearpath Robotics has manufactured a variety of sizes of unmanned ground vehicles (UGVs), companies like Skydio and DJI have manufactured drones to meet multiple different applications, and Boston Dynamics has developed two of the most unique robots on the market: Spot, the robot dog, and Atlas, the humanoid robot. Additionally, in university research groups there are fish-like robots, snake-like robots, worm-like robots, and other designs to cover a wide range of forms and functions. Although not every design ends up changing the landscape of modern robotics, lessons from each design build upon each other.

The self-balancing robot, as shown in Figure \ref{fig:sbb}, is an example of such a system that may not be widely used in robotics, but is nonetheless a valuable problem with implications that are important for more advanced robotics designs. The self-balancing robot is notable because without a controller, it is an unstable system (as I'll show later), and would be useless as a UGV. With a properly designed controller, however, the self-balancing robot is stable and is able to function just as effectively as a 4-wheeled UGV, but with lower cost due to having half the number of wheels, motors, and encoders. Understanding how this system works can help us build more stable UGVs,  humanoid robots, and other designs. 

The objective for this project is to better understand the stability of the uncontrolled system, and to apply controllers to it to successfully stabilize the system. In applying these controllers, it's valuable to see which controller implementations are able to increase stability, and which implementations continue to lead to unstable systems.

The basis for the equations of motion of the self-balancing robot come from the inverted pendulum problem, as shown in Figure \ref{fig:ip}. This system, described in [3], as with our system, is unstable until a controller is applied to maintain the verticality of the pendulum above the cart.

Our setup for the self-balancing robot is similar, however we consider the body of the robot to be the ``pendulum,'' which is directly attached to the two wheels at the base. The output of our system is $\Phi$, the angle from the vertical, which we want to keep at $0^o$, and the input to our system is a torque on the motors, as shown in Figure \ref{fig:sbr_setup}. Although a differential steering system, such as this one, could allow the robot to turn easily, for our purposes we will consider that the two wheels are applied the same torque and thus the robot does not turn, but only moves in the x-direction to stabilize its body. 

For this project, the method involves stability analysis of the uncontrolled system, implementation and tuning of a proportional-integral-derivative (PID) controller, and implementation and tuning of a state-feedback controller utilizing a linear-quadratic regulator (LQR) to calculate the state-feedback gain matrix. 

Although we anticipate the system to be unstable without the implementation of a controller, it is valuable insight to confirm that this is true. We rely on the knowledge that the transfer function for an unstable system will have poles with non-negative real parts. We are able to generate the transfer function for this system by programming our state-space equations, above, in MATLAB, and plotting the poles of the system. 

PID control relies on a reference signal and an error calculation between the reference signal and the system output [1]. In our case, the reference signal is $0^o$ for all time because we want the self-balancing robot to remain entirely vertical. PID control 1) scales the error by a proportional gain, $K_p$, 2) scales the integral of the error by an integral gain, $K_i$, and 3) scales the derivative of the error by a derivative gain, $K_d$, to calculate the input to the system at the next time step, as shown in the equation below. 

Through MATLAB, we can calculate the closed-loop transfer function (CLTF) using the PID controller, and assess the stability of the system similarly by plotting the poles of the transfer function.

State-feedback control relies on changing the pole locations of the original system [4], which is important in this case because we know our unstable system transfer function has poles with positive real components that must be moved to be negative in order for the system to be stable. To accomplish this, we utilize the feedback law \(u = -K \mathbf{x}\) to change our state-space equations from the equations on the left to the equations on the right:

The last control methodology tested was state-feedback control, using LQR to compute the feedback gain matrix. Before implementing this controller, we first guaranteed controllability of our system (A,B) by calculating the rank of the controllability matrix. Since our state has 4 elements, and our controllability matrix had rank 4 (was of full rank) we know that our system is controllable and state-feedback control is a viable approach. 

Using the lqr() command in MATLAB, the system can be tuned using only the R and Q parameters, and the system response to these tunings is shown in Figure \ref{fig:lqr_control}, with the stability of these systems confirmed through the pole plots in Figure \ref{fig:pz_lqr_control}. In the tuning process for the LQR controller, instability was never encountered, which seems to be true for all fully-observable systems upon whom LQR is implemented. Additionally, in the tuned response in Figure \ref{fig:lqr_tuned}, we see that the system has slightly more overshoot, and slightly longer settling time, than the optimal PID controller. These issues could be solved through further tuning of the LQR controller to eliminate these elements of the system response.

Overall, the self-balancing robot system is a particularly interesting system given the inherent instability of the uncontrolled system, but the effectiveness and robustness of the system once a controller is properly applied. This work proved the instability of the uncontrolled system using both system response and by plotting the poles of the transfer function. Additionally, this work showed the sensitivity of the system to different PID control gains, and showed empirically that P-control and PI-control are likely ineffective and impractical control methodologies for this system, as they have a propensity to produce unstable systems. 

When comparing the PID controller and the state-feedback controller using LQR, the stability guarantee from the LQR controller is important for the self-balancing robot system, because the CLTF from the PID controller does not guarantee stability, as we have shown. Although the ideal system response from the LQR controller shown in this report was less optimal than the ideal response from the PID controller, this could be fixed through further tuning of the LQR control parameters, although they are slightly more difficult to tune. 

Further work on this project would move in two directions. 1) Although I have shown the instability of the system under certain constants for PID control, it is important to prove this out mathematically, and to find the stable ranges for the PID control gains. Additionally, if the LQR controller does indeed guarantee stability, it is important to prove this out mathematically as well. 2) While untenable for this project, in control it is always vital to reproduce the performance of the controller on the actualized, real-world system. Self-balancing robots are fairly easily implemented with an Arduino, so comparing PID control and LQR control on the physical system would be a valuable step. 